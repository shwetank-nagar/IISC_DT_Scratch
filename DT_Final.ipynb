{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "#Step 1 - function call required\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from math import log\n",
    "import time\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "# Implement your decision tree below\n",
    "# Used the ID3 algorithm to implement the Decision Tree\n",
    "\n",
    "# Class used for learning and building the Decision Tree using the given Training Set\n",
    "class DecisionTree():\n",
    "    tree = {}\n",
    "    def learn(self, training_set, attributes, target,loop):\n",
    "        self.tree = build_tree(training_set, attributes, target,loop)\n",
    "\n",
    "# Class Node which will be used while classify a test-instance using the tree which was built earlier`\n",
    "class Node():\n",
    "    value = \"\"\n",
    "    children = []\n",
    "\n",
    "    def __init__(self, val, dictionary):\n",
    "        self.value = val\n",
    "        if (isinstance(dictionary, dict)):\n",
    "            self.children = dictionary.keys()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files( filepath):\n",
    "    '''\n",
    "    input - File path of input file. \n",
    "    read file and convert into 2d array.\n",
    "    handles only csv format.\n",
    "    returns Column header and dataset into two different variable.\n",
    "\n",
    "    '''\n",
    "    datastore=[]\n",
    "    final_dataset ={}\n",
    "    with open(filepath,'r') as files:\n",
    "        for line in files.readlines():\n",
    "            lines=line.strip().split(',')\n",
    "            for i in range(len(lines)):\n",
    "                if len(lines[i])==0 or len(lines[i])== None:\n",
    "                    lines[i]=None\n",
    "                elif lines[i][0]=='\"' or lines[i][-1]=='\"':\n",
    "                    lines[i]=lines[i][1:-1]\n",
    "                    value=digit_check(lines[i])\n",
    "                else:\n",
    "                    value=digit_check(lines[i])\n",
    "                if value=='int':\n",
    "                    lines[i]=int(lines[i])\n",
    "                elif value=='float':\n",
    "                    lines[i]=float(lines[i])\n",
    "                else:\n",
    "                    lines[i]=lines[i]\n",
    "            datastore.append(lines)\n",
    "\n",
    "    columns=datastore[0]\n",
    "    dataset=datastore[1:]\n",
    "\n",
    "\n",
    "    return columns,dataset\n",
    "\n",
    "\n",
    "#Step 1.1\n",
    "def digit_check(user_input):\n",
    "    '''\n",
    "    convert string digits into integer / float.\n",
    "    inputs each element of 2d array.\n",
    "    return int/float/string to read_files function.\n",
    "    required - 2d array reads all elements as string char.\n",
    "    '''\n",
    "    try:\n",
    "       val = int(user_input)\n",
    "       return 'int'\n",
    "    except ValueError:\n",
    "      try:\n",
    "        val = float(user_input)\n",
    "        return 'float'\n",
    "      except ValueError:\n",
    "          return 'string'\n",
    "\n",
    "\n",
    "\n",
    "#Step 3.1\n",
    "\n",
    "def random_number(low, high):\n",
    "    \"\"\"\n",
    "    a time based random number generator \n",
    "    uses the random time between a user's input events\n",
    "    returns an integer between low and high-1\n",
    "    \"\"\"\n",
    "    return int(low + int(time.time()*1000) % (high - low))\n",
    "\n",
    "\n",
    "\n",
    "#Step 3.2\n",
    "def random_indices(high,test_size):\n",
    "    '''\n",
    "    generates random sample index.\n",
    "    inputs length of dataset and sample size\n",
    "    returns radom indices\n",
    "\n",
    "    '''\n",
    "    test_indices=[]\n",
    "    while len(test_indices)<test_size:\n",
    "        indices=random_number(len(test_indices),high)\n",
    "        test_indices.append(indices)\n",
    "        test_indices = list( dict.fromkeys(test_indices) )\n",
    "    test_indices.sort()\n",
    "    return test_indices\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 3 - function call required\n",
    "def test_train_split(df,test_size):\n",
    "    '''\n",
    "    input dataset and test size\n",
    "    returns test and training data set\n",
    "\n",
    "    '''\n",
    "    high=len(df)\n",
    "    train_df=[]\n",
    "    if isinstance(test_size,float):\n",
    "        test_size=round(test_size*len(df))\n",
    "    test_indices = random_indices(high,test_size)\n",
    "    test_df=[df[value] for value in test_indices]\n",
    "    for i in range(len(df)):\n",
    "        if i not in test_indices:\n",
    "            train_df.append(df[i])\n",
    "    return test_df,train_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Majority Function which tells which class has more entries in given data-set\n",
    "def default_Y(attributes, data, target):\n",
    "\n",
    "    freq = {}\n",
    "    index = attributes.index(target)\n",
    "\n",
    "    for tuple in data:\n",
    "        if (tuple[index] in freq.keys()):\n",
    "            freq[tuple[index]] += 1 \n",
    "        else:\n",
    "            freq[tuple[index]] = 1\n",
    "\n",
    "    max = 0\n",
    "    major = \"\"\n",
    "\n",
    "    for key in freq.keys():\n",
    "        if freq[key]>max:\n",
    "            max = freq[key]\n",
    "            major = key\n",
    "\n",
    "    return major\n",
    "\n",
    "\n",
    "# This function will get unique values for that particular attribute from the given data\n",
    "def get_values(data, attributes, attr):\n",
    "\n",
    "    index = attributes.index(attr)\n",
    "    values = []\n",
    "\n",
    "    for entry in data:\n",
    "        if entry[index] not in values:\n",
    "            values.append(entry[index])\n",
    "\n",
    "    return values\n",
    "\n",
    "# This function will get all the rows of the data where the chosen \"best\" attribute has a value \"val\"\n",
    "def get_data(data, attributes, best, val):\n",
    "\n",
    "    new_data = [[]]\n",
    "    index = attributes.index(best)\n",
    "\n",
    "    for entry in data:\n",
    "        if (entry[index] == val):\n",
    "            newEntry = []\n",
    "            for i in range(0,len(entry)):\n",
    "                if(i != index):\n",
    "                    newEntry.append(entry[i])\n",
    "            new_data.append(newEntry)\n",
    "\n",
    "    new_data.remove([])    \n",
    "    return new_data\n",
    "\n",
    "\n",
    "# This function is used to build the decision tree using the given data, attributes and the target attributes. \n",
    "# It returns the decision tree in the end.\n",
    "def build_tree(data, attributes, target,loop):\n",
    "    data = data[:]\n",
    "    #print(data)\n",
    "    vals = [record[attributes.index(target)] for record in data]\n",
    "    #print(\"vals: \", vals)\n",
    "    default = default_Y(attributes, data, target)\n",
    "    #print(\"default after calling default_Y: \", default)  \n",
    "    if not data or (len(attributes) - 1) <= 0:\n",
    "        return default\n",
    "    elif vals.count(vals[0]) == len(vals):\n",
    "        return vals[0]\n",
    "    else:\n",
    "        #best = attr_choose(data, attributes, target)\n",
    "        best = attr_choose_new(data, attributes, target,loop)\n",
    "        #print(\"best column to split\",best)\n",
    "        tree = {best:{}}\n",
    "    \n",
    "        for val in get_values(data, attributes, best):\n",
    "            new_data = get_data(data, attributes, best, val)\n",
    "            newAttr = attributes[:]\n",
    "            newAttr.remove(best)\n",
    "            loop+=1\n",
    "            subtree = build_tree(new_data, newAttr, target,loop)\n",
    "            tree[best][val] = subtree\n",
    "    \n",
    "    return tree\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(pi):\n",
    "    '''\n",
    "    return the Entropy of a probability distribution:\n",
    "    entropy(p) = − SUM (Pi * log(Pi) )\n",
    "    defintion:\n",
    "            entropy is a metric to measure the uncertainty of a probability distribution.\n",
    "    entropy ranges between 0 to 1\n",
    "    Low entropy means the distribution varies (peaks and valleys).\n",
    "    High entropy means the distribution is uniform.\n",
    "\n",
    "    '''\n",
    "\n",
    "    total = 0\n",
    "    for p in pi:\n",
    "        p = p / sum(pi)\n",
    "        if p != 0:\n",
    "            total += p * log(p, 2)\n",
    "        else:\n",
    "            total += 0\n",
    "    total *= -1\n",
    "    return total\n",
    "\n",
    "\n",
    "def gain(Y_count_list, feature_list):\n",
    "    '''\n",
    "    return the information gain:\n",
    "    gain(D, A) = entropy(D)−􏰋 SUM ( |Di| / |D| * entropy(Di) )\n",
    "    '''\n",
    "\n",
    "    total = 0\n",
    "    for v in feature_list:\n",
    "        total += sum(v) / sum(Y_count_list) * entropy(v)\n",
    "\n",
    "    gain = entropy(Y_count_list) - total\n",
    "    return gain\n",
    "\n",
    "def convert_feature_to_x_y_relation( feature):\n",
    "    '''\n",
    "    given a feature, this will give all [x,y] in groups\n",
    "    '''\n",
    "    feature_tuple = (tuple(f) for f in feature)\n",
    "    #print(feature_tuple)\n",
    "\n",
    "\n",
    "    ls = []\n",
    "    c= Counter(feature_tuple)\n",
    "    #print(\"Counter: \",c)\n",
    "    for l in c:\n",
    "        ls.append([l[0] , l[1], c[l]])\n",
    "    #print(\"ls\",ls)\n",
    "\n",
    "    key_func = lambda x: x[0]#.strip()\n",
    "    ls.sort()\n",
    "    gr = []  \n",
    "\n",
    "    for key, group in itertools.groupby(ls, key_func):\n",
    "       #print(\"key_func\",key, list(group))\n",
    "       gr.append(list(group))\n",
    "     #print(\"gr\", gr)\n",
    "\n",
    "    gr.sort()\n",
    "    final_list = []\n",
    "    for i,grs in enumerate(gr):\n",
    "        if len(grs) == 2 :\n",
    "            final_list.append([gr[i][0][2],gr[i][1][2]])\n",
    "        elif gr[i][0][1] == 0:\n",
    "            final_list.append([gr[i][0][2],0])\n",
    "        elif gr[i][0][1] == 1:\n",
    "            final_list.append([0,gr[i][0][2]])        \n",
    "    return final_list\n",
    "\n",
    "#############################################Variable dist is a dictionary with Key as feature and value as a list giving feature value and dependent variable#######################################################\n",
    "def get_dictionary_with_x_groups(columname,X,Y):\n",
    "    Variable_dict ={}\n",
    "    for colm in  range(len(columname)-1):\n",
    "        temp=[]\n",
    "        for x,y in zip([x[colm] for x in X] ,Y):\n",
    "            temp.append([x,y])\n",
    "        Variable_dict[columname[colm]] = temp  \n",
    "        temp.append([x,y])\n",
    "    return Variable_dict\n",
    "\n",
    "def give_x_information_gain(Variable_dict, Y_count_list, attributes,loop):\n",
    "    root={}\n",
    "    groups={}\n",
    "    for key in Variable_dict.keys():\n",
    "        #print(\"Groups for Feature %s is %s\" %(key,  dt.convert_feature_to_x_y_relation(Variable_dict[key])))\n",
    "        print(\"--------------------Pass %s-------------\"%loop)\n",
    "        print(\"Information Gain for Feature %s is %s\" %(key,  gain(Y_count_list,convert_feature_to_x_y_relation(Variable_dict[key]))))\n",
    "        root[key] =  gain(Y_count_list,convert_feature_to_x_y_relation(Variable_dict[key]))\n",
    "        groups[key] = Variable_dict[key]\n",
    "    Max_IG = max(root, key=root.get) \n",
    "    root_index = attributes.index(Max_IG)\n",
    "    Max_IG_Value = root[Max_IG]\n",
    "    return Max_IG,root_index,Max_IG_Value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_choose_new(data, attributes, target,loop):\n",
    "    \n",
    "    Variable_dict ={}\n",
    "    #Below gives dataset as dictionary of all columns as key and value as a list of [value of x, value of Y]\n",
    "    X = [x[:-1] for x in data]\n",
    "    Y = [x[-1] for x in data]\n",
    "    #print(\"X\",X)\n",
    "    #print(\"Y\",Y)\n",
    "    Y_count_list = [Y.count(y) for y in set(Y)]\n",
    "    Variable_dict = get_dictionary_with_x_groups(attributes,X,Y)\n",
    "    #print(\"All rows as value and key as column\", Variable_dict)\n",
    "    #print(\"\\n\")\n",
    "\n",
    "    Max_IG,root_index,Max_IG_Value = give_x_information_gain(Variable_dict , Y_count_list, attributes,loop)\n",
    "    return attributes[root_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Testing##########################\n",
    "#print(\"attributes\",attributes)\n",
    "#print(attributes.index('Outlook'))\n",
    "def predict(test_set):\n",
    "    results = []\n",
    "    actual =[]\n",
    "    print(\"\\033[1m\", \"Testing dataset\",\"\\033[0m\",)\n",
    "    print(attributes)\n",
    "    print(\"\\033[1m\", \"Testing dataset\",\"\\033[0m\",)\n",
    "    print(test_set)\n",
    "    for entry in test_set:\n",
    "\n",
    "        tempDict = tree.tree.copy()\n",
    "        #print(\"tempdict\",tempDict)\n",
    "        #print(\"tempdict keys\",tempDict.keys())\n",
    "        result = \"\"\n",
    "        #print(\"instanace\",isinstance(tempDict, dict))\n",
    "        while(isinstance(tempDict, dict)):\n",
    "            #print(1)\n",
    "            param1 = [x for x in tempDict.keys()]\n",
    "            #print(\"param1\",param1)\n",
    "            param2 = tempDict[param1[0]]  # tempDict[tempDict.keys()[0]]\n",
    "            #print(\"param2\",param2) \n",
    "            #root = Node(tempDict.keys()[0], tempDict[tempDict.keys()[0]])\n",
    "            root = Node(param1,param2)\n",
    "            #print(\"root\", root.value)\n",
    "            tempDict = param2\n",
    "            r = root.value\n",
    "            ind =r[0]\n",
    "            index = attributes.index(ind)\n",
    "            value = entry[index]\n",
    "            #print(value)\n",
    "            #print(tempDict.keys())\n",
    "            if(value in tempDict.keys()):\n",
    "                child = Node(value, tempDict[value])\n",
    "                result = tempDict[value]\n",
    "                #print(\"if condition tempdict\",result)\n",
    "                tempDict = tempDict[value]\n",
    "            else:\n",
    "                result = \"Null\"\n",
    "                break\n",
    "        if result != \"Null\":\n",
    "            results.append(result == entry[-1])\n",
    "            actual.append([entry[-1],result])\n",
    "    print(\"\\033[1m\", \"Actual vs predicted values: %s\" % actual, \"\\033[0m\")\n",
    "    return results\n",
    "    \n",
    "    #print(\"results\",results)\n",
    "def accuracy(results):\n",
    "    acc =[]\n",
    "    accuracy = float(results.count(True))/float(len(results))\n",
    "    acc.append(accuracy)\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the mode for dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Pass 0-------------\n",
      "Information Gain for Feature Outlook is 0.19813134764391394\n",
      "--------------------Pass 0-------------\n",
      "Information Gain for Feature Temp is -0.007747062037032015\n",
      "--------------------Pass 0-------------\n",
      "Information Gain for Feature Humidity is -0.028252742871819225\n",
      "--------------------Pass 0-------------\n",
      "Information Gain for Feature Windy is -0.052312970734583186\n",
      "--------------------Pass 1-------------\n",
      "Information Gain for Feature Temp is 0.8112781244591328\n",
      "--------------------Pass 1-------------\n",
      "Information Gain for Feature Humidity is 0.8112781244591328\n",
      "--------------------Pass 1-------------\n",
      "Information Gain for Feature Windy is -0.18872187554086717\n",
      "--------------------Pass 3-------------\n",
      "Information Gain for Feature Temp is -0.07807190511263773\n",
      "--------------------Pass 3-------------\n",
      "Information Gain for Feature Humidity is -0.07807190511263773\n",
      "--------------------Pass 3-------------\n",
      "Information Gain for Feature Windy is 0.17095059445466854\n",
      "--------------------Pass 5-------------\n",
      "Information Gain for Feature Temp is 0.0\n",
      "--------------------Pass 5-------------\n",
      "Information Gain for Feature Humidity is 0.0\n",
      "--------------------Pass 7-------------\n",
      "Information Gain for Feature Humidity is -0.37744375108173434\n",
      "\u001b[1m Training Set \u001b[0m\n",
      "[['Rainy', 'Hot', 'High', 'FALSE', 0],\n",
      " ['Rainy', 'Hot', 'High', 'TRUE', 0],\n",
      " ['Rainy', 'Mild', 'High', 'FALSE', 0],\n",
      " ['Rainy', 'Cool', 'Normal', 'FALSE', 1],\n",
      " ['Overcast', 'Mild', 'High', 'TRUE', 1],\n",
      " ['Overcast', 'Hot', 'Normal', 'FALSE', 1],\n",
      " ['Sunny', 'Mild', 'High', 'FALSE', 1],\n",
      " ['Sunny', 'Cool', 'Normal', 'FALSE', 1],\n",
      " ['Sunny', 'Cool', 'Normal', 'TRUE', 0],\n",
      " ['Sunny', 'Mild', 'High', 'TRUE', 0],\n",
      " ['Sunny', 'Mild', 'High', 'TRUE', 1]]\n",
      "\n",
      "\n",
      "\u001b[1m Trained Tree \u001b[0m\n",
      "{'Outlook': {'Overcast': 1,\n",
      "             'Rainy': {'Temp': {'Cool': 1, 'Hot': 0, 'Mild': 0}},\n",
      "             'Sunny': {'Windy': {'FALSE': 1,\n",
      "                                 'TRUE': {'Temp': {'Cool': 0,\n",
      "                                                   'Mild': {'Humidity': {'High': 0}}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "data = []\n",
    "path =os.path.abspath(os.getcwd())\n",
    "# load and prepare data\n",
    "\n",
    "#filename = os.path.join(path,\"data/data_banknote_authentication.csv\")\n",
    "path =os.path.abspath(os.getcwd())\n",
    "# load and prepare data\n",
    "\n",
    "#filename = os.path.join(path,\"data/data_banknote_authentication.csv\")\n",
    "filename = os.path.join(path,\"data/Golf_data_set.csv\")\n",
    "attributes,dataset=read_files(filename)\n",
    "\n",
    "target = attributes[-1]\n",
    "\n",
    "#####Breaking down the dataset into train_df and test_df, and giving 10% as the split\n",
    "test_set,training_set=test_train_split(dataset,0.3)\n",
    "\n",
    "tree = DecisionTree()\n",
    "loop =0\n",
    "tree.learn( training_set, attributes, target ,loop)\n",
    "print(\"\\033[1m\", \"Training Set\", \"\\033[0m\" )\n",
    "pprint.pprint(training_set)\n",
    "print(\"\\n\")\n",
    "print(\"\\033[1m\", \"Trained Tree\", \"\\033[0m\" )\n",
    "pprint.pprint(tree.tree)\n",
    "\n",
    "#best = attr_choose_new(training_set, attributes, target)\n",
    "#print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Test Set \u001b[0m [['Rainy', 'Hot', 'High', 'TRUE', 0], ['Sunny', 'Cool', 'Normal', 'TRUE', 0], ['Sunny', 'Mild', 'High', 'TRUE', 0], ['Sunny', 'Mild', 'High', 'TRUE', 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1m\", \"Test Set\", \"\\033[0m\" , test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Final Testing code with test data set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Testing dataset \u001b[0m\n",
      "['Outlook', 'Temp', 'Humidity', 'Windy', 'Play_Golf']\n",
      "\u001b[1m Testing dataset \u001b[0m\n",
      "[['Rainy', 'Hot', 'High', 'FALSE', 0], ['Rainy', 'Cool', 'Normal', 'FALSE', 1], ['Overcast', 'Hot', 'High', 'FALSE', 1], ['Sunny', 'Cool', 'Normal', 'FALSE', 1]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-2cfc0e91f11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mavg_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-99b6ef6cd3d7>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(test_set)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mparam1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtempDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m#print(\"param1\",param1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mparam2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# tempDict[tempDict.keys()[0]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;31m#print(\"param2\",param2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m#root = Node(tempDict.keys()[0], tempDict[tempDict.keys()[0]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results = []\n",
    "acc = []\n",
    "results = predict(test_set)\n",
    "acc = accuracy(results)\n",
    "avg_acc = sum(acc)/len(acc)*100\n",
    "print(\"\\033[1m\",\"Accuracy: %.4f\" % avg_acc,\"\\033[0m\",)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the IRIS Data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "learn() missing 1 required positional argument: 'loop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-6b481b352dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\033[1m\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Training Set\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\033[0m\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: learn() missing 1 required positional argument: 'loop'"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "data = []\n",
    "path =os.path.abspath(os.getcwd())\n",
    "# load and prepare data\n",
    "\n",
    "#filename = os.path.join(path,\"data/data_banknote_authentication.csv\")\n",
    "path =os.path.abspath(os.getcwd())\n",
    "# load and prepare data\n",
    "\n",
    "#filename = os.path.join(path,\"data/data_banknote_authentication.csv\")\n",
    "filename = os.path.join(path,\"data/IRIS.csv\")\n",
    "attributes,dataset=read_files(filename)\n",
    "\n",
    "target = attributes[-1]\n",
    "\n",
    "#####Breaking down the dataset into train_df and test_df, and giving 10% as the split\n",
    "test_set,training_set=test_train_split(dataset,0.3)\n",
    "\n",
    "tree = DecisionTree()\n",
    "tree.learn( training_set, attributes, target )\n",
    "print(\"\\033[1m\", \"Training Set\", \"\\033[0m\" )\n",
    "pprint.pprint(training_set)\n",
    "print(\"\\n\")\n",
    "print(\"\\033[1m\", \"Trained Tree\", \"\\033[0m\" )\n",
    "pprint.pprint(tree.tree)\n",
    "\n",
    "#best = attr_choose_new(training_set, attributes, target)\n",
    "#print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Final Testing code with IRIS test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Testing dataset \u001b[0m\n",
      "['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
      "\u001b[1m Testing dataset \u001b[0m\n",
      "[[4.8, 3.4, 1.9, 0.2, 'Iris-setosa'], [5.2, 3.4, 1.4, 0.2, 'Iris-setosa'], [5.2, 4.1, 1.5, 0.1, 'Iris-setosa'], [5, 3.2, 1.2, 0.2, 'Iris-setosa'], [4.9, 3.1, 1.5, 0.1, 'Iris-setosa'], [4.4, 3, 1.3, 0.2, 'Iris-setosa'], [5, 3.5, 1.3, 0.3, 'Iris-setosa'], [4.5, 2.3, 1.3, 0.3, 'Iris-setosa'], [5.3, 3.7, 1.5, 0.2, 'Iris-setosa'], [7, 3.2, 4.7, 1.4, 'Iris-versicolor'], [6.9, 3.1, 4.9, 1.5, 'Iris-versicolor'], [6.3, 3.3, 4.7, 1.6, 'Iris-versicolor'], [4.9, 2.4, 3.3, 1, 'Iris-versicolor'], [5.6, 2.9, 3.6, 1.3, 'Iris-versicolor'], [6.7, 3.1, 4.4, 1.4, 'Iris-versicolor'], [6.2, 2.2, 4.5, 1.5, 'Iris-versicolor'], [5.6, 2.5, 3.9, 1.1, 'Iris-versicolor'], [6.1, 2.8, 4.7, 1.2, 'Iris-versicolor'], [6.4, 2.9, 4.3, 1.3, 'Iris-versicolor'], [6.6, 3, 4.4, 1.4, 'Iris-versicolor'], [6.8, 2.8, 4.8, 1.4, 'Iris-versicolor'], [5.5, 2.4, 3.8, 1.1, 'Iris-versicolor'], [5.5, 2.4, 3.7, 1, 'Iris-versicolor'], [5.8, 2.7, 3.9, 1.2, 'Iris-versicolor'], [6, 2.7, 5.1, 1.6, 'Iris-versicolor'], [6, 3.4, 4.5, 1.6, 'Iris-versicolor'], [6.7, 3.1, 4.7, 1.5, 'Iris-versicolor'], [6.3, 2.3, 4.4, 1.3, 'Iris-versicolor'], [5.6, 3, 4.1, 1.3, 'Iris-versicolor'], [5.5, 2.5, 4, 1.3, 'Iris-versicolor'], [5.5, 2.6, 4.4, 1.2, 'Iris-versicolor'], [5.8, 2.6, 4, 1.2, 'Iris-versicolor'], [5.7, 2.8, 4.1, 1.3, 'Iris-versicolor'], [6.5, 3, 5.8, 2.2, 'Iris-virginica'], [5.7, 2.5, 5, 2, 'Iris-virginica'], [5.8, 2.8, 5.1, 2.4, 'Iris-virginica'], [6.5, 3, 5.5, 1.8, 'Iris-virginica'], [6, 2.2, 5, 1.5, 'Iris-virginica'], [7.2, 3, 5.8, 1.6, 'Iris-virginica'], [7.4, 2.8, 6.1, 1.9, 'Iris-virginica'], [7.9, 3.8, 6.4, 2, 'Iris-virginica'], [6.4, 2.8, 5.6, 2.2, 'Iris-virginica'], [6.3, 2.8, 5.1, 1.5, 'Iris-virginica'], [6.1, 2.6, 5.6, 1.4, 'Iris-virginica'], [6.7, 3.3, 5.7, 2.5, 'Iris-virginica']]\n",
      "\u001b[1m Actual vs predicted values: [['Iris-setosa', 'Iris-setosa'], ['Iris-setosa', 'Iris-setosa'], ['Iris-setosa', 'Iris-setosa'], ['Iris-setosa', 'Iris-setosa'], ['Iris-setosa', 'Iris-setosa'], ['Iris-setosa', 'Iris-setosa'], ['Iris-setosa', 'Iris-setosa'], ['Iris-setosa', 'Iris-setosa'], ['Iris-setosa', 'Iris-setosa'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-versicolor', 'Iris-versicolor'], ['Iris-virginica', 'Iris-virginica'], ['Iris-virginica', 'Iris-virginica'], ['Iris-virginica', 'Iris-virginica'], ['Iris-virginica', 'Iris-virginica'], ['Iris-virginica', 'Iris-versicolor'], ['Iris-virginica', 'Iris-virginica'], ['Iris-virginica', 'Iris-virginica'], ['Iris-virginica', 'Iris-virginica'], ['Iris-virginica', 'Iris-versicolor'], ['Iris-virginica', 'Iris-versicolor'], ['Iris-virginica', 'Iris-virginica']] \u001b[0m\n",
      "\u001b[1m Accuracy: 92.6829 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "acc = []\n",
    "results = predict(test_set)\n",
    "acc = accuracy(results)\n",
    "avg_acc = sum(acc)/len(acc)*100\n",
    "print(\"\\033[1m\",\"Accuracy: %.4f\" % avg_acc,\"\\033[0m\",)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Writing results to a file (DO NOT CHANGE)\\nf = open(\"result.txt\", \"w\")\\nf.write(\"accuracy: %.4f\" % avg_acc)\\nf.close()\\n'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
